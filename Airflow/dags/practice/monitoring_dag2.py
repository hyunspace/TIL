from airflow import DAG
from airflow.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.operators.python import PythonOperator
from datetime import datetime

def print_done():
    print("âœ… B DAG has completed successfully!")

def print_fail():
    print("âŒ B DAG failed. Stopping workflow.")

def skip_if_failed(context):
    raise Exception("Skipping downstream tasks because B DAG failed.")

def print_start():
    print("ğŸš€ Monitoring DAG has started!")

with DAG(
    dag_id="monitoring_dag2",
    start_date=datetime(2024, 1, 1),
    schedule_interval=None,
    catchup=False,
    tags=["jhyun"],
) as dag:

    start = PythonOperator(
        task_id="print_start",
        python_callable=print_start
    )

    trigger_b = TriggerDagRunOperator(
        task_id="trigger_b_dag",
        trigger_dag_id="python_sleep_dag",   # âœ… ì—¬ê¸°ì— íŠ¸ë¦¬ê±°í•  DAG ID ì ê¸°
        wait_for_completion=True,            # âœ… ëë‚  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼
        poke_interval=5,                     # âœ… 5ì´ˆ ê°„ê²©ìœ¼ë¡œ ìƒíƒœ í™•ì¸
        allowed_states=["success"],          # âœ… ì„±ê³µí•´ì•¼ ë‹¤ìŒ íƒœìŠ¤í¬ ì‹¤í–‰ë¨
        failed_states=["failed"],            # âœ… ì‹¤íŒ¨í•˜ë©´ downstream ë§‰í˜
        reset_dag_run=True                   # âœ… ê¸°ì¡´ ì‹¤í–‰ ë‚´ì—­ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ì‹¤í–‰
    )

    after_success = PythonOperator(
        task_id="after_success",
        python_callable=print_done
    )

    after_failure = PythonOperator(
        task_id="after_failure",
        python_callable=print_fail,
        trigger_rule="one_failed"
    )

    start >> trigger_b >> [after_success, after_failure]
